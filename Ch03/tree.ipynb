{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd082b6f5812ea506d741ac7a355c38975a8264e75987c5404f7effc78bc7e6db28",
   "display_name": "Python 3.8.10 64-bit ('d2l': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log \n",
    "\n",
    "def calc_shannon_ent(dataset):\n",
    "    \"\"\"计算香农熵\"\"\"\n",
    "    num_entries = len(dataset)\n",
    "    label_counts = {}\n",
    "    for feat_vec in dataset:\n",
    "        current_label = feat_vec[-1]\n",
    "        if current_label not in label_counts.keys():    # 为了所有可能的分类创建字典\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "    shannon_ent = 0.0 \n",
    "    for key in label_counts:\n",
    "        prob = float(label_counts[key]) / num_entries   # 计算选择此类的概率\n",
    "        shannon_ent -= prob * log(prob, 2)  # 以2为底求对数\n",
    "    return shannon_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    # 这里的label代表的是dataset里面前两列特征的实际含义\n",
    "    # 避免和别的label搞混淆\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dat, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "my_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "calc_shannon_ent(my_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "my_dat[0][-1] = 'maybe'\n",
    "my_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "calc_shannon_ent(my_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, axis, value):\n",
    "    \"\"\"按照指定特征划分数据集\"\"\"\n",
    "    ret_dataset = []\n",
    "    for feat_vec in dataset:\n",
    "        if feat_vec[axis] == value:\n",
    "            reduced_feat_vec = feat_vec[:axis]\n",
    "            reduced_feat_vec.extend(feat_vec[axis+1:])\n",
    "            ret_dataset.append(reduced_feat_vec)    # 抽取符合要求的数据\n",
    "    return ret_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "my_dat, labels = create_dataset()\n",
    "my_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "split_dataset(my_dat, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "split_dataset(my_dat, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature_to_split(dataset):\n",
    "    \"\"\"选择最好的数据划分方式\"\"\"\n",
    "    num_features = len(dataset[0]) - 1\n",
    "    base_entroy = calc_shannon_ent(dataset)\n",
    "    best_info_gain = 0.0; best_feature = -1 # 初始化原数据集的香农熵\n",
    "    for i in range(num_features):\n",
    "        feat_list = [example[i] for example in dataset]\n",
    "        unique_vals = set(feat_list)    # 创建唯一的分类标签set\n",
    "        new_entroy = 0.0 \n",
    "        for value in unique_vals:\n",
    "            sub_dataset = split_dataset(dataset, i, value)\n",
    "            prob = len(sub_dataset) / float(len(dataset))\n",
    "            new_entroy += prob * calc_shannon_ent(sub_dataset)  # 计算每种划分方式的信息熵\n",
    "        info_gain = base_entroy - new_entroy\n",
    "        if (info_gain > best_info_gain):\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i    # 计算最多信息增益下的划分特征\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "my_dat, labels = create_dataset()\n",
    "my_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "choose_best_feature_to_split(my_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def majority_cnt(class_list):\n",
    "    \"\"\"返回数量最多的类\"\"\"\n",
    "    class_count = {}\n",
    "    for vote in class_list:\n",
    "        if vote not in class_count.keys():\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    \n",
    "    sorted_class_count = sorted(class_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, labels):\n",
    "    \"\"\"创建树\"\"\"\n",
    "    class_list = [example[-1] for example in dataset]\n",
    "    if class_list.count(class_list[0]) == len(class_list):  # 类别完全相同，停止划分\n",
    "        return class_list[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        return majority_cnt(class_list)     # 遍历完所有特征时返回出现次数最多的\n",
    "    best_feat = choose_best_feature_to_split(dataset)\n",
    "    best_feat_label = labels[best_feat]\n",
    "    my_tree = {best_feat_label: {}}\n",
    "    del(labels[best_feat])\n",
    "    feat_vals = [example[best_feat] for example in dataset]\n",
    "    unique_vals = set(feat_vals)\n",
    "    for value in unique_vals:\n",
    "        sub_labels = labels[:]\n",
    "        my_tree[best_feat_label][value] =\\\n",
    "             create_tree(split_dataset(dataset, best_feat, value), sub_labels)\n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "my_dat, labels = create_dataset()\n",
    "my_tree = create_tree(my_dat, labels)\n",
    "my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用文本注释绘制树\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "decision_node = dict(boxstyle='sawtooth', fc='0.8')\n",
    "leaf_node = dict(boxstyle='round4', fc='0.8')\n",
    "arrow_args = dict(arrowstyle='<-')\n",
    "\n",
    "def plot_node(node_text, center_pt, parent_pt, node_type):\n",
    "    create_plot.ax1.annotate(node_text, xy=parent_pt,  xycoords='axes fraction',\n",
    "             xytext=center_pt, textcoords='axes fraction',\n",
    "             va=\"center\", ha=\"center\", bbox=node_type, arrowprops=arrow_args)\n",
    "\n",
    "def create_plot():\n",
    "    fig = plt.figure(1, facecolor='white')\n",
    "    fig.clf()\n",
    "    "
   ]
  }
 ]
}