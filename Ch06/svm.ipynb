{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "82b6f5812ea506d741ac7a355c38975a8264e75987c5404f7effc78bc7e6db28"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_mat = []; label_mat = []\n",
    "    with open(filename) as fr:\n",
    "        for line in fr.readlines():\n",
    "            line_arr = line.strip().split('\\t')\n",
    "            data_mat.append([float(line_arr[0]), float(line_arr[1])])\n",
    "            label_mat.append(float(line_arr[2]))\n",
    "    return data_mat, label_mat\n",
    "\n",
    "def select_jrand(i, m):\n",
    "    # 随机选择另一个优化的j,不等于i\n",
    "    j = i \n",
    "    while j == i:\n",
    "        j = np.random.randint(0, m)\n",
    "    return j\n",
    "\n",
    "def clip_alpha(aj, H, L):\n",
    "    aj = max(aj, L)\n",
    "    aj = min(aj, H)\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "data_arr, label_arr = load_dataset('testSet.txt')\n",
    "print(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smo_simple(data, classlabels, C, toler, max_iter):\n",
    "    \"\"\"\n",
    "    C:常数\n",
    "    toler:容错率\n",
    "    \"\"\"\n",
    "    data_mat = np.mat(data)\n",
    "    label_mat = np.mat(classlabels).transpose()\n",
    "    b = 0; m,n = np.shape(data_mat)\n",
    "    alphas = np.mat(np.zeros((m, 1)))\n",
    "    num = 0\n",
    "    while (num < max_iter):\n",
    "        alpha_pair_changed = 0 \n",
    "        for i in range(m):\n",
    "            fXi = float(np.multiply(alphas, label_mat).T * \\\n",
    "                (data_mat * data_mat[i, :].T)) + b  # 计算出的类别\n",
    "            Ei = fXi - float(label_mat[i])  # 误差Ei，根据此优化\n",
    "            if ((label_mat[i] * Ei < -toler) and (alphas[i] < C)) or \\\n",
    "                ((label_mat[i] * Ei > toler) and (alphas[i] > 0) and \\\n",
    "                    (alphas[i] > 0)):   # 如果alpha可以改更改进入优化过程\n",
    "                j = select_jrand(i, m)  # 随机选择第二个alpha\n",
    "                fXj = float(np.multiply(alphas, label_mat).T * \\\n",
    "                    (data_mat * data_mat[j, :].T)) + b \n",
    "                Ej = fXj - float(label_mat[j])\n",
    "                alpha_i_old = alphas[i].copy()\n",
    "                alpha_j_old = alphas[j].copy() # \n",
    "                if (label_mat[i] != label_mat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L == H: \n",
    "                    # print(\"L==H\")\n",
    "                    continue\n",
    "                eta = 2.0 * data_mat[i,:] * data_mat[i,:].T - \\\n",
    "                    data_mat[i,:]*data_mat[i,:].T - data_mat[j,:]*data_mat[j,:].T   # eta是alpha[j]的最优修改量\n",
    "                if eta >=0: \n",
    "                    # print(\"eta>=0\")\n",
    "                    continue \n",
    "                alphas[j] -= label_mat[j]*(Ei - Ej)/eta\n",
    "                alphas[j] = clip_alpha(alphas[j], H, L)\n",
    "                if (abs(alphas[j] - alpha_j_old) < 0.00001):\n",
    "                    # print(\"j not moving enough\")\n",
    "                    continue\n",
    "                alphas[i] += label_mat[j] * label_mat[i] * (alpha_j_old - alphas[j])   # i的修改方向和j相反\n",
    "                # 设置常数项\n",
    "                b1 = b - Ei \\\n",
    "                    - label_mat[i] * (alphas[i] - alpha_i_old) * data_mat[i,:] * data_mat[i,:].T \\\n",
    "                    - label_mat[j] * (alphas[j] - alpha_j_old) * data_mat[i,:] * data_mat[j,:].T\n",
    "                b2 = b - Ej \\\n",
    "                    - label_mat[i] * (alphas[i] - alpha_i_old) * data_mat[i,:] * data_mat[j,:].T \\\n",
    "                    - label_mat[j] * (alphas[j] - alpha_j_old) * data_mat[j,:] * data_mat[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]):\n",
    "                    b = b1 \n",
    "                elif (0 < alphas[j]) and (C > alphas[j]):\n",
    "                    b = b2 \n",
    "                else:\n",
    "                    b = (b1 + b2) / 2.0\n",
    "                alpha_pair_changed += 1\n",
    "                # print(\"iter : %d i:%d, pairs changed %d\" % \\\n",
    "                #     (num, i, alpha_pair_changed))\n",
    "        if (alpha_pair_changed == 0): \n",
    "            num += 1\n",
    "        else: \n",
    "            num = 0\n",
    "        # print(\"iteration number: %d\" % num)\n",
    "    return b, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b, alphas = smo_simple(data_arr, label_arr, 0.6, 0.001, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[-3.95445957]])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[5.55111512e-17, 9.50073353e-14, 8.04304540e-14, 6.95624114e-16,\n",
       "         1.29588653e-01, 2.30116273e-13, 2.72351586e-15, 2.53015230e-01,\n",
       "         5.52873719e-14, 2.18602046e-13, 5.55111512e-17, 3.82603883e-01,\n",
       "         5.55111512e-17, 7.87044041e-15, 1.94757405e-14]])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "alphas[alphas>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.326297, 0.265213] -1.0\n[3.634009, 1.730537] -1.0\n[3.125951, 0.293251] -1.0\n[2.123252, -0.783563] -1.0\n[4.658191, 3.507396] -1.0\n[3.223038, -0.552392] -1.0\n[2.301095, -0.533988] -1.0\n[3.457096, -0.082216] -1.0\n[3.023938, -0.057392] -1.0\n[2.893743, -1.643468] -1.0\n[1.870457, -1.04042] -1.0\n[6.080573, 0.418886] 1.0\n[2.529893, 0.662657] -1.0\n[1.966279, -1.840439] -1.0\n[2.912122, -0.202359] -1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if alphas[i] > 0.0:\n",
    "        print(data_arr[i], label_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用完整的platt SMO 优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStruct:\n",
    "    def __init__(self, data_mat, classlabels, C, toler):\n",
    "        self.X = data_mat\n",
    "        self.label_mat = classlabels\n",
    "        self.C = C \n",
    "        self.tol = toler \n",
    "        self.m = np.shape(data_mat)[0]\n",
    "        self.alphas = np.mat(np.zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.e_cache = np.mat(np.zeros((self.m, 2)))\n",
    "\n",
    "\n",
    "def calc_ek(ds, k):\n",
    "    fXk = np.multiply(ds.alphas, ds.label_mat).T *\\\n",
    "        (ds.X * ds.X[k,:].T) + ds.b\n",
    "    Ek = float(fXk[0][0]) - float(ds.label_mat[k])\n",
    "    return Ek\n",
    "\n",
    "def select_j(i, ds, Ei):\n",
    "    max_k = -1\n",
    "    max_deltaE = 0\n",
    "    Ej = 0  # 内循环中的启发式方法\n",
    "    ds.e_cache[i] = [1, Ei]\n",
    "    valid_Ecache_lst = np.nonzero(np.array(ds.e_cache[:, 0]))[0]\n",
    "    if (len(valid_Ecache_lst) > 1):\n",
    "        # >1说明至之前计算过别的E，选择最大的进行优化\n",
    "        for k in valid_Ecache_lst:\n",
    "            if k == i:\n",
    "                continue\n",
    "            Ek = calc_ek(ds, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > max_deltaE):\n",
    "                max_k = k\n",
    "                max_deltaE = deltaE \n",
    "        return max_k, Ej \n",
    "    else:\n",
    "        # 第一次循环就直接随机选择一个j\n",
    "        j = select_jrand(i, ds.m)\n",
    "        Ej = calc_ek(ds, j)\n",
    "    return j, Ej \n",
    "\n",
    "\n",
    "def updateEk(ds, k):\n",
    "    Ek = calc_ek(ds, k)\n",
    "    ds.e_cache[k] = [1, Ek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, ds):\n",
    "    Ei = calc_ek(ds, i)\n",
    "    if ((ds.label_mat[i] * Ei < -ds.tol) and (ds.alphas[i] < ds.C)) or \\\n",
    "        ((ds.label_mat[i] * Ei > ds.tol) and (ds.alphas[i] > 0)):\n",
    "        j, Ej = select_j(i, ds, Ei) # 第二个alpha选择中的启发式方法\n",
    "        alpha_i_old = ds.alphas[i].copy()\n",
    "        alpha_j_old = ds.alphas[j].copy()\n",
    "        if (ds.label_mat[i] != ds.label_mat[j]):\n",
    "            L = max(0, ds.label_mat[j] - ds.label_mat[i])\n",
    "            H = min(ds.C, ds.C + ds.label_mat[j] - ds.label_mat[i])\n",
    "        else:\n",
    "            L = max(0, ds.label_mat[j] + ds.label_mat[i] - ds.C)\n",
    "            H = min(ds.C, ds.label_mat[j] + ds.label_mat[i])\n",
    "        if L == H:\n",
    "            # print(\"L==H\")\n",
    "            return 0 \n",
    "        eta = 2.0 * ds.X[i,:] * ds.X[i,:].T - \\\n",
    "                    ds.X[i,:]*ds.X[i,:].T - ds.X[j,:]*ds.X[j,:].T\n",
    "        if eta >=0: \n",
    "            # print(\"eta>=0\")\n",
    "            return 0 \n",
    "        ds.alphas[j] -= ds.label_mat[j]*(Ei - Ej)/eta\n",
    "        ds.alphas[j] = clip_alpha(ds.alphas[j], H, L)\n",
    "        updateEk(ds, j)\n",
    "        if (abs(alphas[j] - alpha_j_old) < 0.00001):\n",
    "            # print(\"j not moving enough\")\n",
    "            return 0\n",
    "        ds.alphas[i] += ds.label_mat[j] * ds.label_mat[i] * (alpha_j_old - ds.alphas[j])\n",
    "        updateEk(ds, i) # 更新误差缓存\n",
    "        b1 = ds.b - Ei \\\n",
    "            - ds.label_mat[i] * (ds.alphas[i] - alpha_i_old) * ds.X[i,:] * ds.X[i,:].T \\\n",
    "            - ds.label_mat[j] * (ds.alphas[j] - alpha_j_old) * ds.X[i,:] * ds.X[j,:].T\n",
    "        b2 = ds.b - Ej \\\n",
    "            - ds.label_mat[i] * (ds.alphas[i] - alpha_i_old) * ds.X[i,:] * ds.X[j,:].T \\\n",
    "            - ds.label_mat[j] * (ds.alphas[j] - alpha_j_old) * ds.X[j,:] * ds.X[j,:].T\n",
    "        if (0 < ds.alphas[i]) and (ds.C > ds.alphas[i]):\n",
    "            ds.b = b1 \n",
    "        elif (0 < ds.alphas[j]) and (ds.C > ds.alphas[j]):\n",
    "            ds.b = b2 \n",
    "        else:\n",
    "            ds.b = (b1 + b2) / 2.0\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smo_p(data_mat, classlabels, C, toler, max_iter, kTup=('lin', 0)):\n",
    "    \"\"\"完整SMO算法中的外循环代码\"\"\"\n",
    "    ds = DataStruct(np.mat(data_mat), np.mat(classlabels).transpose(), C, toler, kTup)\n",
    "    num = 0\n",
    "    entire_set = True \n",
    "    alpha_pairs_changed = 0\n",
    "    while (num < max_iter) and ((alpha_pairs_changed > 0) or (entire_set)):\n",
    "        alpha_pairs_changed = 0\n",
    "        if entire_set:  # 遍历所有值\n",
    "            for i in range(ds.m):\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "            # print(\"Fullset, iter: %d i: %d, pairs changed %d\" %\\\n",
    "            #     (num, i, alpha_pairs_changed))\n",
    "            num += 1\n",
    "        else:       # 遍历非边界值\n",
    "            non_bounds = np.nonzero((np.array(ds.alphas) > 0) * (np.array(ds.alphas) < C))[0]\n",
    "            for i in non_bounds:\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "                # print(\"non-bound, iter: %d i: %d, pairs changed %d\" %\\\n",
    "                #     (num, i, alpha_pairs_changed))\n",
    "                num += 1\n",
    "        if entire_set:\n",
    "            entire_set = False \n",
    "        elif alpha_pairs_changed == 0:\n",
    "            entire_set = True \n",
    "        # print(\"iteration number: %d\" % num)\n",
    "    return ds.b, ds.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 5 positional arguments but 6 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-0687ff1179d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testSet.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmo_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-fecc3d83960f>\u001b[0m in \u001b[0;36msmo_p\u001b[0;34m(data_mat, classlabels, C, toler, max_iter, kTup)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmo_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkTup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"完整SMO算法中的外循环代码\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataStruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasslabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkTup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mentire_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "data_arr, label_arr = load_dataset('testSet.txt')\n",
    "b, alphas = smo_p(data_arr, label_arr, 0.6, 0.001, 40)"
   ]
  },
  {
   "source": [
    "b"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[-3.95445957]])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[5.55111512e-17, 9.50073353e-14, 8.04304540e-14, 6.95624114e-16,\n",
       "         1.29588653e-01, 2.30116273e-13, 2.72351586e-15, 2.53015230e-01,\n",
       "         5.52873719e-14, 2.18602046e-13, 5.55111512e-17, 3.82603883e-01,\n",
       "         5.55111512e-17, 7.87044041e-15, 1.94757405e-14]])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "alphas[alphas>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.326297, 0.265213] -1.0\n[3.634009, 1.730537] -1.0\n[3.125951, 0.293251] -1.0\n[2.123252, -0.783563] -1.0\n[4.658191, 3.507396] -1.0\n[3.223038, -0.552392] -1.0\n[2.301095, -0.533988] -1.0\n[3.457096, -0.082216] -1.0\n[3.023938, -0.057392] -1.0\n[2.893743, -1.643468] -1.0\n[1.870457, -1.04042] -1.0\n[6.080573, 0.418886] 1.0\n[2.529893, 0.662657] -1.0\n[1.966279, -1.840439] -1.0\n[2.912122, -0.202359] -1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if alphas[i] > 0.0:\n",
    "        print(data_arr[i], label_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ws(alphas, data_arr, classlabels):\n",
    "    X = np.mat(data_arr)\n",
    "    label_mat = np.mat(classlabels).transpose()\n",
    "    m,n = np.shape(X)\n",
    "    w = np.zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += np.multiply(alphas[i] * label_mat[i], X[i,:].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = calc_ws(alphas, data_arr, label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.8481042 ],\n",
       "       [-0.27344941]])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "label_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[-2.09317163]])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "data_arr[1] * np.mat(ws) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "label_arr[1]"
   ]
  },
  {
   "source": [
    "# 核函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_mat = []; label_mat = []\n",
    "    with open(filename) as fr:\n",
    "        for line in fr.readlines():\n",
    "            line_arr = line.strip().split('\\t')\n",
    "            data_mat.append([float(line_arr[0]), float(line_arr[1])])\n",
    "            label_mat.append(float(line_arr[2]))\n",
    "    return data_mat, label_mat\n",
    "\n",
    "def select_jrand(i, m):\n",
    "    # 随机选择另一个优化的j,不等于i\n",
    "    j = i \n",
    "    while j == i:\n",
    "        j = np.random.randint(0, m)\n",
    "    return j\n",
    "\n",
    "def clip_alpha(aj, H, L):\n",
    "    aj = max(aj, L)\n",
    "    aj = min(aj, H)\n",
    "    return aj\n",
    "\n",
    "def calc_ek(ds, k):\n",
    "    fXk = np.multiply(ds.alphas, ds.label_mat).T *\\\n",
    "        (ds.X * ds.X[k,:].T) + ds.b\n",
    "    Ek = float(fXk[0][0]) - float(ds.label_mat[k])\n",
    "    return Ek\n",
    "\n",
    "def select_j(i, ds, Ei):\n",
    "    max_k = -1\n",
    "    max_deltaE = 0\n",
    "    Ej = 0  # 内循环中的启发式方法\n",
    "    ds.e_cache[i] = [1, Ei]\n",
    "    valid_Ecache_lst = np.nonzero(np.array(ds.e_cache[:, 0]))[0]\n",
    "    if (len(valid_Ecache_lst) > 1):\n",
    "        # >1说明至之前计算过别的E，选择最大的进行优化\n",
    "        for k in valid_Ecache_lst:\n",
    "            if k == i:\n",
    "                continue\n",
    "            Ek = calc_ek(ds, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > max_deltaE):\n",
    "                max_k = k\n",
    "                max_deltaE = deltaE \n",
    "        return max_k, Ej \n",
    "    else:\n",
    "        # 第一次循环就直接随机选择一个j\n",
    "        j = select_jrand(i, ds.m)\n",
    "        Ej = calc_ek(ds, j)\n",
    "    return j, Ej \n",
    "\n",
    "\n",
    "def updateEk(ds, k):\n",
    "    Ek = calc_ek(ds, k)\n",
    "    ds.e_cache[k] = [1, Ek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_trans(X, A, ktup):\n",
    "    m,n = np.shape(X)\n",
    "    K = np.mat(np.zeros((m, 1)))\n",
    "    if ktup[0] == 'lin':\n",
    "        K = X * A.T \n",
    "    elif ktup[0] == 'rbf':\n",
    "        for j in range(m):\n",
    "            delta_row = X[j, :] - A \n",
    "            K[j] = delta_row * delta_row.T \n",
    "        K = np.exp(K / (-1*ktup[1]**2)) # 元素间的除法\n",
    "    else:\n",
    "        raise NameError('Houston We Have a Problem --\\\n",
    "            That Kernel is not recognized')\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStruct:\n",
    "    def __init__(self, data_mat, classlabels, C, toler, ktup):\n",
    "        self.X = data_mat\n",
    "        self.label_mat = classlabels\n",
    "        self.C = C \n",
    "        self.tol = toler \n",
    "        self.m = np.shape(data_mat)[0]\n",
    "        self.alphas = np.mat(np.zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.e_cache = np.mat(np.zeros((self.m, 2)))\n",
    "        self.K = np.mat(np.zeros((self.m, self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernel_trans(self.X, self.X[i,:], ktup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, ds):\n",
    "    Ei = calc_ek(ds, i)\n",
    "    if ((ds.label_mat[i] * Ei < -ds.tol) and (ds.alphas[i] < ds.C)) or \\\n",
    "        ((ds.label_mat[i] * Ei > ds.tol) and (ds.alphas[i] > 0)):\n",
    "        j, Ej = select_j(i, ds, Ei) # 第二个alpha选择中的启发式方法\n",
    "        alpha_i_old = ds.alphas[i].copy()\n",
    "        alpha_j_old = ds.alphas[j].copy()\n",
    "        if (ds.label_mat[i] != ds.label_mat[j]):\n",
    "            L = max(0, ds.label_mat[j] - ds.label_mat[i])\n",
    "            H = min(ds.C, ds.C + ds.label_mat[j] - ds.label_mat[i])\n",
    "        else:\n",
    "            L = max(0, ds.label_mat[j] + ds.label_mat[i] - ds.C)\n",
    "            H = min(ds.C, ds.label_mat[j] + ds.label_mat[i])\n",
    "        if L == H:\n",
    "            # print(\"L==H\")\n",
    "            return 0 \n",
    "        eta = 2.0 * ds.K[i,j] - ds.K[i,i] - ds.K[j,j]\n",
    "        if eta >=0: \n",
    "            # print(\"eta>=0\")\n",
    "            return 0 \n",
    "        ds.alphas[j] -= ds.label_mat[j]*(Ei - Ej)/eta\n",
    "        ds.alphas[j] = clip_alpha(ds.alphas[j], H, L)\n",
    "        updateEk(ds, j)\n",
    "        if (abs(ds.alphas[j] - alpha_j_old) < 0.00001):\n",
    "            # print(\"j not moving enough\")\n",
    "            return 0\n",
    "        ds.alphas[i] += ds.label_mat[j] * ds.label_mat[i] * (alpha_j_old - ds.alphas[j])\n",
    "        updateEk(ds, i) # 更新误差缓存\n",
    "        b1 = ds.b - Ei \\\n",
    "            - ds.label_mat[i] * (ds.alphas[i] - alpha_i_old) * ds.K[i,i] \\\n",
    "            - ds.label_mat[j] * (ds.alphas[j] - alpha_j_old) * ds.K[i,j]\n",
    "        b2 = ds.b - Ej \\\n",
    "            - ds.label_mat[i] * (ds.alphas[i] - alpha_i_old) * ds.K[i,j] \\\n",
    "            - ds.label_mat[j] * (ds.alphas[j] - alpha_j_old) * ds.K[j,j]\n",
    "        if (0 < ds.alphas[i]) and (ds.C > ds.alphas[i]):\n",
    "            ds.b = b1 \n",
    "        elif (0 < ds.alphas[j]) and (ds.C > ds.alphas[j]):\n",
    "            ds.b = b2 \n",
    "        else:\n",
    "            ds.b = (b1 + b2) / 2.0\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calc_ek(ds, k):\n",
    "    fXk = np.multiply(ds.alphas, ds.label_mat).T *\\\n",
    "        ds.K[:,k] + ds.b\n",
    "    Ek = float(fXk[0][0]) - float(ds.label_mat[k])\n",
    "    return Ek\n",
    "\n",
    "def smo_p(data_mat, classlabels, C, toler, max_iter, kTup=('lin', 0)):\n",
    "    ds = DataStruct(np.mat(data_mat), np.mat(classlabels).transpose(), C, toler, kTup)\n",
    "    num = 0\n",
    "    entire_set = True \n",
    "    alpha_pairs_changed = 0\n",
    "    while (num < max_iter) and ((alpha_pairs_changed > 0) or (entire_set)):\n",
    "        alpha_pairs_changed = 0\n",
    "        if entire_set:  # 遍历所有值\n",
    "            for i in range(ds.m):\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "            num += 1\n",
    "        else:       # 遍历非边界值\n",
    "            non_bounds = np.nonzero((ds.alphas.A > 0) * (ds.alphas.A < C))[0]\n",
    "            for i in non_bounds:\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "            num += 1\n",
    "        if entire_set:\n",
    "            entire_set = False \n",
    "        elif alpha_pairs_changed == 0:\n",
    "            entire_set = True \n",
    "    return ds.b, ds.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 利用核函数进行分类的径向基测试函数\n",
    "def test_rbf(k1 = 1.3):\n",
    "    data_arr, label_arr = load_dataset('testSetRBF.txt')\n",
    "    b, alphas = smo_p(data_arr, label_arr, 200, 0.0001, 100, ('rbf', k1))\n",
    "    data_mat = np.mat(data_arr)\n",
    "    label_mat = np.mat(label_arr).transpose()\n",
    "    svInd = np.nonzero(np.array(alphas) > 0)[0]   # 构建支持向量矩阵\n",
    "    sVs = data_mat[svInd]\n",
    "    labelSV = label_mat[svInd]\n",
    "    print(\"There are %d Support Vectors\" % sVs.shape[0])\n",
    "    m, n = data_mat.shape\n",
    "    error_count = 0\n",
    "    for i in range(m):\n",
    "        kernel_eval = kernel_trans(sVs, data_mat[i,:], ('rbf', k1))\n",
    "        predict = kernel_eval.T * np.multiply(labelSV, alphas[svInd]) + b \n",
    "        if np.sign(predict[0][0]) != np.sign(label_arr[i]):\n",
    "            error_count += 1\n",
    "    print(\"The training error rate is %f\" % (float(error_count) / m))\n",
    "\n",
    "    data_arr, label_arr = load_dataset('testSetRBF2.txt')\n",
    "    error_count = 0\n",
    "    data_mat = np.mat(data_arr)\n",
    "    label_mat = np.mat(label_arr)\n",
    "    m, n = data_mat.shape\n",
    "    for i in range(m):\n",
    "        kernel_eval = kernel_trans(sVs, data_mat[i,:], ('rbf', k1))\n",
    "        predict = kernel_eval.T * np.multiply(labelSV, alphas[svInd]) + b \n",
    "        if np.sign(predict[0][0]) != np.sign(label_arr[i]):\n",
    "            error_count += 1\n",
    "    print(\"The test error rate is %f\" %(float(error_count) / m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 27 Support Vectors\n",
      "The training error rate is 0.440000\n",
      "The test error rate is 0.370000\n"
     ]
    }
   ],
   "source": [
    "test_rbf(k1=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 17 Support Vectors\nThe training error rate is 0.040000\nThe test error rate is 0.060000\n"
     ]
    }
   ],
   "source": [
    "test_rbf(k1=1)"
   ]
  },
  {
   "source": [
    "# 手写字符识别问题"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    \"\"\"将手写的数字图片转化为向量\"\"\"\n",
    "    return_vec = np.zeros((1, 1024))\n",
    "    with open(filename) as fr:  # python这样打开文件不用再close()\n",
    "        for i in range(32):\n",
    "            line_str = fr.readline()\n",
    "            for j in range(32):\n",
    "                return_vec[0, 32*i+j] = int(line_srt[j])\n",
    "    \n",
    "    return return_vec\n",
    "\n",
    "def load_images(dirname):\n",
    "    from os import listdir \n",
    "    hw_labels = []\n",
    "    training_file_lst = listdir(dirname)\n",
    "    m = len(training_file_lst)\n",
    "    training_mat = np.zeros((m, 1024))\n",
    "    for i in range(m):\n",
    "        filename = training_file_lst[i]\n",
    "        filestr = filename.split('.')[0]\n",
    "        class_num = int(filestr.split('_')[0])\n",
    "        if class_num == 9:\n",
    "            hw_labels.append(-1)\n",
    "        else:\n",
    "            hw_labels.append(1)\n",
    "        training_mat[i,:] = img2vector('%s/%s' %(dirname, filename))\n",
    "    return training_mat, hw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDigits(kTup=('rbf', 10)):\n",
    "    dataArr,labelArr = load_images('trainingDigits')\n",
    "    b,alphas = smo_p(dataArr, labelArr, 200, 0.0001, 10, kTup)\n",
    "    datMat=np.mat(dataArr); labelMat = np.mat(labelArr).transpose()\n",
    "    svInd=np.nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] \n",
    "    labelSV = labelMat[svInd]\n",
    "    print (\"there are %d Support Vectors\" % shape(sVs)[0])\n",
    "    m,n = np.shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1\n",
    "    print (\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "\n",
    "    dataArr,labelArr = load_images('testDigits')\n",
    "    errorCount = 0\n",
    "    datMat=np.mat(dataArr); labelMat = np.mat(labelArr).transpose()\n",
    "    m,n = np.shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if np.sign(predict)!=np.sign(labelArr[i]): errorCount += 1    \n",
    "    print (\"the test error rate is: %f\" % (float(errorCount)/m) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trainingDigits/5_135.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-13fd4668016e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestDigits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkTup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-e00d2a809717>\u001b[0m in \u001b[0;36mtestDigits\u001b[0;34m(kTup)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestDigits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkTup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainingDigits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmo_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkTup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatMat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlabelMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msvInd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-8360f7924fac>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mhw_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtraining_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-8360f7924fac>\u001b[0m in \u001b[0;36mimg2vector\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"将手写的数字图片转化为向量\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mreturn_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# python这样打开文件不用再close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mline_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trainingDigits/5_135.txt'"
     ]
    }
   ],
   "source": [
    "testDigits(kTup=('rbf', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}