{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "ec442b799e2b8e292ace03b1db8d183cfcb00ca6ec5d31b580096caf96682ec2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 核函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def kernel_trans(X, A, kTup):\n",
    "    m,n = np.shape(X)\n",
    "    K = np.mat(np.zeros((m,1)))\n",
    "    if kTup[0]=='lin': K = X * A.T   #linear kernel\n",
    "    elif kTup[0]=='rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j,:] - A\n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        K = np.exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab\n",
    "    else: raise NameError('Houston We Have a Problem -- \\\n",
    "    That Kernel is not recognized')\n",
    "    return K\n",
    "\n",
    "class optStruct:\n",
    "    def __init__(self, datamat, classlabels, C, toler, kTup):\n",
    "        self.X = datamat \n",
    "        self.label_mat = classlabels\n",
    "        self.C = C \n",
    "        self.tol = toler \n",
    "        self.m = np.shape(datamat)[0]\n",
    "        self.alphas = np.mat(np.zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.ecache = np.mat(np.zeros((self.m, 2)))\n",
    "        self.K = np.mat(np.zeros((self.m, self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernel_trans(self.X, self.X[i,:], kTup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    data_mat = []; label_mat = []\n",
    "    with open(filename) as fr:\n",
    "        for line in fr.readlines():\n",
    "            line_arr = line.strip().split('\\t')\n",
    "            data_mat.append([float(line_arr[0]), float(line_arr[1])])\n",
    "            label_mat.append(float(line_arr[2]))\n",
    "    return data_mat, label_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.label_mat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.label_mat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = select_j(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy()\n",
    "        if (oS.label_mat[i] != oS.label_mat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: return 0\n",
    "        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel\n",
    "        if eta >= 0: return 0\n",
    "        oS.alphas[j] -= oS.label_mat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clip_alpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): return 0\n",
    "        oS.alphas[i] += oS.label_mat[j]*oS.label_mat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.label_mat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.label_mat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b - Ej- oS.label_mat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.label_mat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smo_p(data_mat, classlabels, C, toler, max_iter, kTup):\n",
    "    \"\"\"完整SMO算法中的外循环代码\"\"\"\n",
    "    ds = optStruct(np.mat(data_mat), np.mat(classlabels).transpose(), C, toler, kTup)\n",
    "    num = 0\n",
    "    entire_set = True \n",
    "    alpha_pairs_changed = 0\n",
    "    while (num < max_iter) and ((alpha_pairs_changed > 0) or (entire_set)):\n",
    "        alpha_pairs_changed = 0\n",
    "        if entire_set:  # 遍历所有值\n",
    "            for i in range(ds.m):\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "            # print(\"Fullset, iter: %d i: %d, pairs changed %d\" %\\\n",
    "            #     (num, i, alpha_pairs_changed))\n",
    "            num += 1\n",
    "        else:       # 遍历非边界值\n",
    "            non_bounds = np.nonzero((np.array(ds.alphas) > 0) * (np.array(ds.alphas) < C))[0]\n",
    "            for i in non_bounds:\n",
    "                alpha_pairs_changed += innerL(i, ds)\n",
    "                # print(\"non-bound, iter: %d i: %d, pairs changed %d\" %\\\n",
    "                #     (num, i, alpha_pairs_changed))\n",
    "                num += 1\n",
    "        if entire_set:\n",
    "            entire_set = False \n",
    "        elif alpha_pairs_changed == 0:\n",
    "            entire_set = True \n",
    "        # print(\"iteration number: %d\" % num)\n",
    "    return ds.b, ds.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEk(oS, k):\n",
    "    fXk = float(np.multiply(oS.alphas,oS.label_mat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.label_mat[k])\n",
    "    return Ek\n",
    "\n",
    "def updateEk(ds, k):\n",
    "    Ek = calcEk(ds, k)\n",
    "    ds.ecache[k] = [1, Ek]\n",
    "\n",
    "def select_jrand(i, m):\n",
    "    # 随机选择另一个优化的j,不等于i\n",
    "    j = i \n",
    "    while j == i:\n",
    "        j = np.random.randint(0, m)\n",
    "    return j\n",
    "\n",
    "def select_j(i, ds, Ei):\n",
    "    max_k = -1\n",
    "    max_deltaE = 0\n",
    "    Ej = 0  # 内循环中的启发式方法\n",
    "    ds.ecache[i] = [1, Ei]\n",
    "    valid_Ecache_lst = np.nonzero(np.array(ds.ecache[:, 0]))[0]\n",
    "    if (len(valid_Ecache_lst) > 1):\n",
    "        # >1说明至之前计算过别的E，选择最大的进行优化\n",
    "        for k in valid_Ecache_lst:\n",
    "            if k == i:\n",
    "                continue\n",
    "            Ek = calcEk(ds, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > max_deltaE):\n",
    "                max_k = k\n",
    "                max_deltaE = deltaE \n",
    "        return max_k, Ej \n",
    "    else:\n",
    "        # 第一次循环就直接随机选择一个j\n",
    "        j = select_jrand(i, ds.m)\n",
    "        Ej = calcEk(ds, j)\n",
    "    return j, Ej \n",
    "\n",
    "def clip_alpha(aj, H, L):\n",
    "    aj = max(aj, L)\n",
    "    aj = min(aj, H)\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRbf(k1=1.3):\n",
    "    data_arr, label_arr = load_dataset('testSetRBF.txt')\n",
    "    b, alphas = smo_p(data_arr, label_arr, 200, 0.0001, 10000, ('rbf', k1))\n",
    "    datamat = np.mat(data_arr)\n",
    "    labelmat = np.mat(label_arr).transpose()\n",
    "    svInd = np.nonzero(alphas.A>0)[0]\n",
    "    sVs = datamat[svInd]\n",
    "    labelSV = labelmat[svInd]\n",
    "    print(\"There are %d support vectors\" % np.shape(sVs)[0])\n",
    "    m,n = np.shape(datamat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs, datamat[i,:], ('rbf', k1))\n",
    "        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b \n",
    "        if np.sign(predict) != np.sign(label_arr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The training error rate is %f\" % (float(errorCount)/m))\n",
    "\n",
    "    data_arr, label_arr = load_dataset('testSetRBF2.txt')\n",
    "    errorCount = 0\n",
    "    datamat = np.mat(data_arr)\n",
    "    labelmat = np.mat(label_arr).transpose()\n",
    "    m,n = np.shape(datamat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs, datamat[i,:], ('rbf', k1))\n",
    "        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b \n",
    "        if np.sign(predict) != np.sign(label_arr[i]):\n",
    "            errorCount += 1\n",
    "    print(\"The testing error rate is %f\" % (float(errorCount)/m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 38 support vectors\nThe training error rate is 0.100000\nThe testing error rate is 0.150000\n"
     ]
    }
   ],
   "source": [
    "testRbf()"
   ]
  },
  {
   "source": [
    "# 手写识别问题"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = np.zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "def loadImages(dirName):\n",
    "    from os import listdir\n",
    "    hwLabels = []\n",
    "    trainingFileList = listdir(dirName)           #load the training set\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = np.zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]     #take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        if classNumStr == 9: hwLabels.append(-1)\n",
    "        else: hwLabels.append(1)\n",
    "        trainingMat[i,:] = img2vector('%s/%s' % (dirName, fileNameStr))\n",
    "    return trainingMat, hwLabels  \n",
    "\n",
    "def testDigits(kTup=('rbf', 10)):\n",
    "    dataArr,labelArr = loadImages('trainingDigits')\n",
    "    b,alphas = smo_p(dataArr, labelArr, 200, 0.0001, 10000, kTup)\n",
    "    datMat = np.mat(dataArr)\n",
    "    labelMat = np.mat(labelArr).transpose()\n",
    "    svInd = np.nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] \n",
    "    labelSV = labelMat[svInd]\n",
    "    print (\"there are %d Support Vectors\" % np.shape(sVs)[0])\n",
    "    m,n = np.shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * np.multiply(labelSV,alphas[svInd]) + b\n",
    "        if np.sign(predict) != np.sign(labelArr[i]): errorCount += 1\n",
    "    print (\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    \n",
    "    dataArr,labelArr = loadImages('testDigits')\n",
    "    errorCount = 0\n",
    "    datMat = np.mat(dataArr)\n",
    "    labelMat = np.mat(labelArr).transpose()\n",
    "    m,n = np.shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernel_trans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * np.multiply(labelSV,alphas[svInd]) + b\n",
    "        if np.sign(predict) != np.sign(labelArr[i]): errorCount += 1    \n",
    "    print (\"the test error rate is: %f\" % (float(errorCount)/m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are 93 Support Vectors\n",
      "the training error rate is: 0.000000\n",
      "the test error rate is: 0.005376\n"
     ]
    }
   ],
   "source": [
    "testDigits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}